{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## \u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043e\u043f\u0446\u0438\u0439 \n", "\u041d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\u0439 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043d\u0430\u0431\u043e\u0440\u0430 \u043e\u043f\u0446\u0438\u0439, \u043a\u0430\u0436\u0434\u0430\u044f \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0430 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0442\u044c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0435 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0432 \u0437\u0430\u0434\u0430\u0447\u0435 \u0442\u0430\u043a\u0441\u0438. \u0414\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c QLearningAgent, \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043c\u044b \u043d\u0430\u043f\u0438\u0441\u0430\u043b\u0438 \u043d\u0430 \u043e\u0434\u043d\u043e\u043c \u0438\u0437 \u043f\u0440\u043e\u0448\u043b\u044b\u0445 \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u043e\u0432. "]}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [], "source": ["# \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0444\u0430\u0439\u043b\u044b \u0438 \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0435\n", "import gym\n", "import random\n", "import numpy as np\n", "\n", "environment = gym.make('Taxi-v2')\n", "environment.render()\n"]}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [], "source": ["# \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u0441 Q-\u0430\u0433\u0435\u043d\u0442\u0430 \u0438\u0437 \u043f\u0440\u043e\u0448\u043b\u043e\u0433\u043e \u0437\u0430\u043d\u044f\u0442\u0438\u044f\n", "from q_agent import QLearningAgent"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u0417\u0430\u0434\u0430\u043d\u0438\u0435 1 \n", "\u0420\u0430\u0437\u0431\u0435\u0440\u0435\u043c\u0441\u044f \u043a\u0430\u043a \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u0430 \u0441\u0440\u0435\u0434\u0430 Taxi: https://github.com/openai/gym/blob/master/gym/envs/toy_text/taxi.py\n", "\n", "\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c 4 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\u0445 Taxi, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0446\u0435\u043b\u044c\u044e \u0430\u0433\u0435\u043d\u0442\u0430 \u0431\u0443\u0434\u0435\u0442 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0435 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u0442\u043e\u0447\u0435\u043a: R, G, B, Y \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0435\u043d\u043d\u043e. "]}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [], "source": ["class TaxiStepWrapper(gym.Wrapper):\n", "    def __init__(self, env, target_id, target_reward):\n", "        super().__init__(env)\n", "        self._target = target_id\n", "        self._target_reward = target_reward\n", "\n", "    def _step(self, action):\n", "        # \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b (state, reward, _, obs),\n", "        # \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u0435\u0440\u0435\u0434\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u0430, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u043c\u0435\u0442\u043e\u0434 step \n", "        # \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0438 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0430\u044e\u0449\u0438\u043c\n", "        # \u0434\u043b\u044f \u043d\u0430\u0448\u0435\u0433\u043e \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f\n", "        # \u0438\u0437\u043c\u0435\u043d\u044f\u0435\u043c \u0432\u043e\u0437\u043d\u0430\u0433\u0440\u0430\u0436\u0434\u0435\u043d\u0438\u0435 (reward) \u0438 \n", "        # \u0444\u043b\u0430\u0433 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u044d\u043f\u0438\u0437\u043e\u0434\u0430 (is_done)\n", "        # \u0437\u0430 \u043a\u0430\u0436\u0434\u043e\u0435 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435 \u0431\u0443\u0434\u0435\u043c \u0434\u0430\u0432\u0430\u0442\u044c \u0432\u043e\u0437\u043d\u0430\u0433\u0440\u0430\u0436\u0434\u0435\u043d\u0438\u0435 \n", "        # -1, \u0437\u0430 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0438 - self._target_reward\n", "        #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "        \n", "        raise NotImplementedError", "        \n", "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "        \n", "\n", "        return state, reward, is_done, obs\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430\u0448\u0443 \u043e\u0431\u0435\u0440\u0442\u043a\u0443 (wrapper), \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u0443\u044e \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e.  \u041f\u043e\u0440\u044f\u0434\u043e\u043a \u0442\u043e\u0447\u0435\u043a \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c  R, G, Y, B."]}, {"cell_type": "code", "execution_count": 56, "metadata": {}, "outputs": [], "source": ["for target in range(4):\n", "    # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0441 \u0437\u0430\u0434\u0430\u043d\u043d\u044b\u043c \u0446\u0435\u043b\u0435\u0432\u044b\u043c \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435\u043c\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n", "    \n", "    # \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u0443\u044e \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e,\n", "    # \u043f\u043e\u043a\u0430 \u044d\u043f\u0438\u0437\u043e\u0434 \u043d\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0438\u0442\u0441\u044f\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n", "\n", "    wrapped_env.render()\n", "    print(\"state:{s} reward:{r}\\n\".format(**locals()))\n"]}, {"cell_type": "code", "execution_count": 57, "metadata": {}, "outputs": [], "source": ["# \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u043c play_and_train, \n", "# \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u044b \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043b\u0438 \u043d\u0430 \u043f\u0440\u043e\u0448\u043b\u043e\u043c \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u0435\n", "def play_and_train(env, agent, t_max=10 ** 4):\n", "    total_discounted_reward = 0.0\n", "    s = env.reset()\n", "    for t in range(t_max):\n", "        a = agent.get_action(s)\n", "        next_s, r, done, _ = env.step(a)\n", "        agent.update(s, a, next_s, r)\n", "        s = next_s\n", "        total_discounted_reward += r\n", "        if done:\n", "            break\n", "    return total_discounted_reward\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u0417\u0430\u0434\u0430\u043d\u0438\u0435 2 \n", "1. \u041e\u0431\u0443\u0447\u0438\u043c \u0430\u0433\u0435\u043d\u0442\u043e\u0432 \u043d\u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430\u043c\u0438 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f\u0445.\n", "2. \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0443\u043f\u0440\u043e\u0449\u0435\u043d\u043d\u044b\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u043e\u043f\u0446\u0438\u0439, \u043a\u0430\u0436\u0434\u0430\u044f \u043e\u043f\u0446\u0438\u044f \u0431\u0443\u0434\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044e, \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0439 \u0438 \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043d\u0435\u0447\u043d\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0439."]}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [], "source": ["n_actions = environment.action_space.n\n", "\n", "# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0443\u0434\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0430\u0433\u0435\u043d\u0442\u044b\n", "params = {\"alpha\": 0.1, \"epsilon\": 0.1, \n", "\"gamma\": 0.99, \"get_legal_actions\": lambda s: range(4)}\n", "\n", "# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0430\u0433\u0435\u043d\u0442\u043e\u0432 \n", "agents_for_options = [QLearningAgent(**params)\\\n", "                      for _ in range(4)]\n", "\n", "for index in range(4):\n", "    # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0441 \u0437\u0430\u0434\u0430\u043d\u043d\u044b\u043c \u0446\u0435\u043b\u0435\u0432\u044b\u043c \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435\u043c, \n", "    # \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u0430\u0433\u0435\u043d\u0442\u043e\u0432\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n"]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": ["# \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u043e\u043f\u0446\u0438\u0438\n", "class Option:\n", "    def __init__(self, policy, termination_prob, initial):\n", "        self.policy = policy\n", "        self.termination_prob = termination_prob\n", "        self.initial_states = initial\n", "\n", "    def can_start(self, state):\n", "        return state in self.initial_states\n", "\n", "    def terminate(self, state):\n", "        return random.random() <= self.termination_prob[\n", "            state]\n", "\n", "    def get_action(self, state):\n", "        return self.policy.get_action(state)"]}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [], "source": ["options = []\n", "for index, agent in enumerate(agents_for_options):\n", "    # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c termination_prob, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \n", "    # \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044e  \u043d\u0443\u0436\u043d\u043e \u0437\u0430\u0434\u0430\u0442\u044c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \n", "    # \u043e\u043f\u0446\u0438\u0438. \u0412 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0437\u0430\u0434\u0430\u0434\u0438\u043c 1.0 \u0438\u043b\u0438 0.0, \n", "    # \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f.\n", "    # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e initial, \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0432 \u043d\u0435\u0433\u043e \n", "    # \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f, \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043e\u043f\u0446\u0438\u044f \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \n", "    # \u0432\u044b\u0437\u0432\u0430\u043d\u0430 (\u0432\u0441\u0435 \u043a\u0440\u043e\u043c\u0435 \u0446\u0435\u043b\u0435\u0432\u044b\u0445)\n", "    termination_prob = {}\n", "    initial_states = set()\n", "    termination_states = set()\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n", "\n", "    options.append(Option(policy=agent, \\\n", "    termination_prob=termination_prob, initial=initial))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u0417\u0430\u0434\u0430\u043d\u0438\u0435 3\n", "\u041d\u0430\u043f\u0438\u0448\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u044c \u043e\u043f\u0446\u0438\u044e \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u0434\u0438\u0441\u043a\u043e\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \u0432\u043e\u0437\u043d\u0430\u0433\u0440\u0430\u0436\u0434\u0435\u043d\u0438\u0435, \u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u0447\u0438\u0441\u043b\u043e \u0441\u043e\u0432\u0435\u0440\u0448\u0435\u043d\u043d\u044b\u0445 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0439\n", "$$ R = r_{1} + \\gamma r_{2} + \\gamma^{2} r_{3} + \\dots + \\gamma^{t-1}r_{t}$$"]}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [], "source": ["def apply_option(option, gamma, env, debug=False):\n", "    reward = 0\n", "    steps = 0\n", "\n", "    if not option.can_start(state):\n", "        raise KeyError\n", "    \n", "    # \u0412\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0443\u0435\u043c \u0441\u043e \u0441\u0440\u0435\u0434\u043e\u0439 \u043f\u043e\u043a\u0430 \u043e\u043f\u0446\u0438\u044f \u0438\u043b\u0438 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \n", "    # \u043d\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0438\u0442\u0441\u044f, \u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0434\u0438\u0441\u043a\u043e\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \n", "    # \u0432\u043e\u0437\u043d\u0430\u0433\u0440\u0430\u0436\u0434\u0435\u043d\u0438\u0435 reward (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c steps),\n", "    # \u0442\u0430\u043a\u0436\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u043c render \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f, \u043f\u0440\u0438 \u0444\u043b\u0430\u0433\u0435 - debug\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n", "    # state, reward, is_done, obs\n", "    return s, reward, d, obs\n"]}, {"cell_type": "code", "execution_count": 62, "metadata": {}, "outputs": [], "source": ["# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0440\u0430\u0431\u043e\u0442\u0443 \u043c\u0435\u0442\u043e\u0434\u0430\n", "env = gym.make('Taxi-v2')\n", "s = env.reset()\n", "\n", "r = apply_option(options[0], 0.99, env, debug=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u041a\u0430\u0436\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0432\u0441\u0435 \u0445\u043e\u0440\u043e\u0448\u043e, \u043d\u043e \u043c\u044b \u0437\u0430\u0431\u044b\u043b\u0438 \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0432\u0430\u0440\u0438\u0430\u043d\u0442, \u043a\u043e\u0433\u0434\u0430 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440 \u043c\u043e\u0436\u0435\u0442 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0432 \u0442\u0430\u043a\u0441\u0438! \u041f\u0435\u0440\u0435\u0432\u0435\u0434\u0435\u043c \u0441\u0440\u0435\u0434\u0443 \u0432 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435, \u0433\u0434\u0435 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u0430 \u043c\u044b \u0443\u0436\u0435 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043b\u0438 \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u043a\u0430\u043a \u0432\u0435\u0434\u0435\u0442 \u0441\u0435\u0431\u044f  \u043e\u0434\u043d\u0430 \u0438\u0437 \u043e\u043f\u0446\u0438\u0439."]}, {"cell_type": "code", "execution_count": 63, "metadata": {}, "outputs": [], "source": ["s = env.reset()\n", "env.unwrapped.s = 499\n", "env.render()\n", "print(\"\\n\" * 2)\n", "r = apply_option(options[0], 0.99, env, debug=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u0417\u0430\u0434\u0430\u043d\u0438\u0435 4\n", "\u0412\u0438\u0434\u0438\u043c, \u0447\u0442\u043e \u043e\u043f\u0446\u0438\u0438 \u043d\u0435 \u043e\u0431\u0443\u0447\u0438\u043b\u0438\u0441\u044c \u0434\u0435\u0439\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c \u0432 \u0442\u0430\u043a\u043e\u0439 \u0441\u0438\u0442\u0443\u0430\u0446\u0438\u0438. \n", "\u0418\u0441\u043f\u0440\u0430\u0432\u0438\u043c \u043d\u0430\u0448\u0443 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u043e\u043f\u0446\u0438\u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0445 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0439 \u0441\u0440\u0435\u0434\u044b \u0438 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u0438\u0445 \u0437\u0430\u043d\u043e\u0432\u043e."]}, {"cell_type": "code", "execution_count": 64, "metadata": {}, "outputs": [], "source": ["def play_and_train_modified(env, agent, t_max=10 ** 4):\n", "    # \u0417\u0430\u0434\u0430\u0434\u0438\u043c \u043d\u043e\u0432\u0443\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u044e play_and_train, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \n", "    # \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u0442 \u043b\u044e\u0431\u043e\u0435 \n", "    # \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u0441\u0440\u0435\u0434\u044b,\u0432\u043a\u043b\u044e\u0447\u0430\u044f \u0438 \u0442\u043e, \u043a\u043e\u0433\u0434\u0430 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440 \n", "    # \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u0442\u0430\u043a\u0441\u0438\n", "\n", "    total_discounted_reward = 0.0\n", "    s = env.reset()\n", "    \n", "    # \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0435 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u0441\u0440\u0435\u0434\u044b\n", "    # (\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043c\u0435\u0442\u043e\u0434 env.uwrapped)\n", "    #~~~~~~~~ \u0412\u0430\u0448 \u043a\u043e\u0434 \u0437\u0434\u0435\u0441\u044c ~~~~~~~~~~~", "    \n", "    raise NotImplementedError", "    \n", "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n", "    \n", "\n", "    for t in range(t_max):\n", "        a = agent.get_action(s)\n", "        next_s, r, done, _ = env.step(a)\n", "        agent.update(s, a, next_s, r)\n", "        s = next_s\n", "        total_discounted_reward += r\n", "        if done:\n", "            break\n", "    return total_discounted_reward\n", "\n", "\n", "for index in range(4):\n", "    for _ in range(5250):\n", "        wrapped_env = TaxiStepWrapper(env=environment, \n", "                target_id=index, target_reward=50)\n", "        play_and_train_modified(env=wrapped_env, \n", "                agent=agents_for_options[index])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u0417\u0430\u043f\u0443\u0441\u0442\u0438\u043c \u0434\u0430\u043d\u043d\u0443\u044e \u044f\u0447\u0435\u0439\u043a\u0443 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437 \u0438 \u0443\u0431\u0435\u0434\u0438\u043c\u0441\u044f, \u0447\u0442\u043e \u0430\u0433\u0435\u043d\u0442 \u043e\u0431\u0443\u0447\u0438\u043b\u0441\u044f \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0441\u043b\u0443\u0447\u0430\u0435\u0432!"]}, {"cell_type": "code", "execution_count": 65, "metadata": {}, "outputs": [], "source": ["env = environment\n", "s = env.reset()\n", "\n", "env.unwrapped.s = random.randint(0, 499)\n", "apply_option(options[0], 0.99, env, debug=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0432 \u0438\u0435\u0440\u0430\u0440\u0445\u0438\u044e\n", "\u0420\u0435\u0430\u043b\u0438\u0437\u0443\u0439\u0442\u0435 \u0438\u0435\u0440\u0430\u0440\u0445\u0438\u044e, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u044b\u0435 (\u043e\u043f\u0446\u0438\u0438 \u0438\u0437 \u043e\u0434\u043d\u043e\u0433\u043e \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f) \u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043e\u043f\u0446\u0438\u0438."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u044b\u0435 \u043e\u043f\u0446\u0438\u0438 (\u043e\u043f\u0446\u0438\u0438 \u0438\u0437 \u043e\u0434\u043d\u043e\u0433\u043e \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f: \u043f\u043e\u0441\u0430\u0434\u043a\u0430 \u0438 \u0432\u044b\u0441\u0430\u0434\u043a\u0430 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u0430):"]}, {"cell_type": "code", "execution_count": 66, "metadata": {}, "outputs": [], "source": ["# \u0434\u043b\u044f \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0439 4-5 (pickup, dropoff) \u0441\u043e\u0437\u0434\u0430\u0435\u043c \n", "# \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u044b\u0435 \u043e\u043f\u0446\u0438\u0438:\n", "class OneActionAgent:\n", "    def __init__(self, action):\n", "        self.action = action\n", "    \n", "    def get_action(self, state):\n", "        return self.action\n", "    \n", "    def update(*args, **kwargs):\n", "        pass\n", "\n", "options = options[:4]    \n", "for action in range(4, 6):\n", "    # \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u0430\u044f \u043e\u043f\u0446\u0438\u044f \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442\u0441\u044f \u0432 \u043b\u044e\u0431\u043e\u043c \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0438, \n", "    # \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442 \u043b\u044e\u0431\u043e\u0435 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435 \u0438 \u0437\u0430\u0432\u0435\u0440\u0448\u0430\u0435\u0442\u0441\u044f\n", "    initial = set(range(environment.observation_space.n))\n", "    termination_prob = {_:1.0 \\\n", "    for _ in  range(environment.observation_space.n)}   \n", "    options.append(Option(policy=OneActionAgent(action), \n", "    termination_prob=termination_prob, initial=initial))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u044b\u0435 \u043e\u043f\u0446\u0438\u0438:"]}, {"cell_type": "code", "execution_count": 67, "metadata": {}, "outputs": [], "source": ["env = environment\n", "s = env.reset()\n", "\n", "env.unwrapped.s = random.randint(0, 499)\n", "apply_option(options[0], 0.99, env, debug=True)\n", "apply_option(options[4], 0.99, env, debug=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### \u0420\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u043e\u0431\u0435\u0440\u0442\u043a\u0443 \u0434\u043b\u044f \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0432\u043c\u0435\u0441\u0442\u043e \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0439 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442 \u043e\u043f\u0446\u0438\u0438 (\u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0432\u0445\u043e\u0434\u0430 - \u0441\u043f\u0438\u0441\u043e\u043a \u043e\u043f\u0446\u0438\u0439):"]}, {"cell_type": "code", "execution_count": 68, "metadata": {}, "outputs": [], "source": ["class OptionTaxiStepWrapper(gym.Wrapper):\n", "    def __init__(self, env, options, gamma=0.99):\n", "        self.options = options\n", "        self.gamma = gamma\n", "        super().__init__(env)\n", "\n", "    def _step(self, action):\n", "        state, reward, is_done, obs =\\\n", "        apply_option(self.options[action],\n", "            self.gamma, self.unwrapped)\n", "        return state, reward, is_done, obs\n"]}, {"cell_type": "code", "execution_count": 69, "metadata": {}, "outputs": [], "source": ["option_agent = QLearningAgent(alpha=0.1, epsilon=0.1,\n", "                              gamma=0.99,\n", "                              get_legal_actions=lambda\n", "                                  s: range(len(options)))\n", "\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "from IPython.display import clear_output\n", "\n", "# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0435, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0435\u0435 \u043e\u043f\u0446\u0438\u0438\n", "env = OptionTaxiStepWrapper(gym.make('Taxi-v2'),\n", "                            options=options)\n", "rewards = []\n", "for episode in range(500):\n", "    rewards.append(\n", "        play_and_train(env=env, agent=option_agent))\n", "\n", "    if episode % 100 == 0:\n", "        clear_output(True)\n", "        option_agent.epsilon *= 0.99\n", "        plt.plot(rewards)\n", "        plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.5.2"}}, "nbformat": 4, "nbformat_minor": 2}
