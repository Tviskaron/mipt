{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МТИИ 2021: Python\n",
    "## Семинар 2:\n",
    "## Часть 1: Краткое руководство по написанию кода на Python (Python Enhanced Proposal - PEP8). \n",
    "## Часть 2: Регулярные выражения. Токенизация. Лемматизация. Стемминг. Модель биграмм.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1:\n",
    "\n",
    "PEP8 можно считать набором правил для написания кода на Python. Данный документы покрывает следующие пункты:\n",
    "\n",
    "* Introduction\n",
    "* A Foolish Consistency is the Hobgoblin of Little Minds\n",
    "* Code Lay-out\n",
    "    * Indentation\n",
    "    * Tabs or Spaces?\n",
    "    * Maximum Line Length\n",
    "    * Should a Line Break Before or After a Binary Operator?\n",
    "    * Blank Lines\n",
    "    * Source File Encoding\n",
    "    * Imports\n",
    "    * Module Level Dunder Names\n",
    "* String Quotes\n",
    "* Whitespace in Expressions and Statements\n",
    "    * Pet Peeves\n",
    "    * Other Recommendations\n",
    "* When to Use Trailing Commas\n",
    "* Comments\n",
    "    * Block Comments\n",
    "    * Inline Comments\n",
    "    * Documentation Strings\n",
    "* Naming Conventions\n",
    "    * Overriding Principle\n",
    "    * Descriptive: Naming Styles\n",
    "    * Prescriptive: Naming Conventions\n",
    "        * Names to Avoid\n",
    "        * ASCII Compatibility\n",
    "        * Package and Module Names\n",
    "        * Class Names\n",
    "        * Type Variable Names\n",
    "        * Exception Names\n",
    "        * Global Variable Names\n",
    "        * Function and Variable Names\n",
    "        * Function and Method Arguments\n",
    "        * Method Names and Instance Variables\n",
    "        * Constants\n",
    "        * Designing for Inheritance\n",
    "    * Public and Internal Interfaces\n",
    "* Programming Recommendations\n",
    "    * Function Annotations\n",
    "    * Variable Annotations\n",
    "\n",
    "### Вопрос 1: Какой из двух вариантов написания кода правильный? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 1\n",
    "foo = long_function_name(var_one, var_two,\n",
    "                         var_three, var_four)\n",
    "\n",
    "def long_function_name(\n",
    "        var_one, var_two, var_three,\n",
    "        var_four):\n",
    "    print(var_one)\n",
    "\n",
    "foo = long_function_name(\n",
    "    var_one, var_two,\n",
    "    var_three, var_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 2\n",
    "foo = long_function_name(var_one, var_two,\n",
    "    var_three, var_four)\n",
    "\n",
    "def long_function_name(\n",
    "    var_one, var_two, var_three,\n",
    "    var_four):\n",
    "    print(var_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 2: Что лучше использовать для отсутпов, табуляцию или пробелы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 3: Нужно ли вводить ограничение на максимальную длину строки? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 4: Какой из двух вариантов написания кода правильный? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 1\n",
    "income = (gross_wages +\n",
    "          taxable_interest +\n",
    "          (dividends - qualified_dividends) -\n",
    "          ira_deduction -\n",
    "          student_loan_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 2\n",
    "income = (gross_wages\n",
    "          + taxable_interest\n",
    "          + (dividends - qualified_dividends)\n",
    "          - ira_deduction\n",
    "          - student_loan_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 5: Какую кодировку нужно использовать в python3? Почему всегда utf-8?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 6: Какие из трех  вариантов написания кода являются правильными? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 1\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 2\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 3\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 7: Какой тип ковыче нужно использовать для задания строк (одинарный или двойной)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 8: Использование пробелов. Выберите правильные варианты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 1\n",
    "spam(ham[1], {eggs: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 2 \n",
    "spam( ham[ 1 ], { eggs: 2 } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 1\n",
    "foo = (0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 2\n",
    "bar = (0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 1 \n",
    "ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:]\n",
    "ham[lower:upper], ham[lower:upper:], ham[lower::step]\n",
    "ham[lower+offset : upper+offset]\n",
    "ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)]\n",
    "ham[lower + offset : upper + offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант 2\n",
    "ham[lower + offset:upper + offset]\n",
    "ham[1: 9], ham[1 :9], ham[1:9 :3]\n",
    "ham[lower : : upper]\n",
    "ham[ : upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы рассмотрели лишь часть руководства PEP8, более подробно вы можете изучить его самостоятельно в [документации](https://www.python.org/dev/peps/pep-0008/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Часть 2:\n",
    "\n",
    "## 1. Регулярные выражения\n",
    "\n",
    "Регулярные выражения (regular expressions, RegExp) —\n",
    "это формальный язык для операций с подстроками.\n",
    "\n",
    "Чаще всего регулярные выражения используются для:\n",
    "* поиска в строке;\n",
    "* разбиения строки на подстроки;\n",
    "* замены части строки;\n",
    "* валидации (проверки).\n",
    "\n",
    "## Синтаксис:\n",
    "<img src='https://raw.githubusercontent.com/hse-ds/iad-applied-ds/master/2020/seminars/seminar11/r.png'>\n",
    "\n",
    "\n",
    "\n",
    "## Онлайн упражнения\n",
    "https://regexone.com/\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения в Python\n",
    "\n",
    "Основные методы:\n",
    "```\n",
    "• re.match() — поиск совпадения в начале строки\n",
    "• re.search() — поиск первого совпадения\n",
    "• re.findall() — поиск всех совпадений (возвр. список)\n",
    "• re.split() — разбиение строки\n",
    "• re.sub() — замена подстроки\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match\n",
    "ищет по заданному шаблону в начале строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.match('ab+c.', 'abcdefghijkabcabcd') # ищем по шаблону 'ab+c.' \n",
    "print (result) # совпадение найдено:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.group(0)) # выволмс найденное совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.match('abc.', 'abdefghijkabcabc')\n",
    "print(result) # совпадение не найдено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1:\n",
    "Проверьте, начинаются ли строки c заглавной буквы и если да, то вывести эту заглавную букву. Придумайте свои примеры строк для проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search\n",
    "ищет по всей строке, возвращает только первое найденное совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Проверьте, есть ли в строке вопросительный знак. Придумайте свои примеры для проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы: \n",
    "1) почему нет последнего abc?\n",
    "2) почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = \"Я, ты, мы, вы, они. Случайность? Не думаю!\"\n",
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Нашел он полон двор услуги;\n",
    "К покойнику со всех сторон\n",
    "Съезжались недруги и други,\n",
    "Охотники до похорон.\n",
    "Покойника похоронили.\n",
    "Попы и гости ели, пили\n",
    "И после важно разошлись,\n",
    "Как будто делом занялись.\n",
    "Вот наш Онегин — сельский житель,\n",
    "Заводов, вод, лесов, земель\n",
    "Хозяин полный, а досель\n",
    "Порядка враг и расточитель,\n",
    "И очень рад, что прежний путь\n",
    "Переменил на что-нибудь.\"\"\"\n",
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5:\n",
    "Замените все цифры на звездочки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = \"7253dvhfks0340921934uhgj34l4321\"\n",
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6\n",
    "Для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7\n",
    "Вернуть первое слово строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 8\n",
    "Вернуть список доменов (@gmail.com, @rest.biz и т.д.) из списка адресов электронной почты:\n",
    "\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Токенизация\n",
    "\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью split. Но split упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем данные и доставляем необходимые библиотеки\n",
    "!wget https://raw.githubusercontent.com/hse-ds/iad-applied-ds/master/2020/seminars/seminar11/alice.txt -N\n",
    "!wget https://raw.githubusercontent.com/hse-ds/iad-applied-ds/master/2020/seminars/seminar11/dinos.txt -N\n",
    "!pip install nltk\n",
    "!pip install pymystem3==0.1.10\n",
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Задание 9\n",
    "\n",
    "Откройте и запишите в одну текстовую строку файл alice.txt.\n",
    "\n",
    "Ответьте на вопросы:\n",
    "\n",
    "    Сколько всего символов в файле?\n",
    "    Какой текст написан в последней строке файла? (Подсказка: в какой переменной содержится эта строка?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Задание 10\n",
    "\n",
    "Создайте и скомпилируйте регулярное выражения для разбиения полученной строки на токены. Не забудьте про дефис и букву ё.\n",
    "\n",
    "Найдите все токены с помощью этого регулярного выражения, ответьте на вопросы:\n",
    "\n",
    "    Сколько токенов получилось?\n",
    "    Какой токен первый?\n",
    "    Какой токен последний?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация в nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как .split() :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – лемме. Почему это хорошо?\n",
    "\n",
    "    Во-первых, мы хотим рассматривать как отдельную фичу каждое слово, а не каждую его отдельную форму.\n",
    "    Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "\n",
    "### Mystem\n",
    "\n",
    "https://yandex.ru/dev/mystem/doc/index-docpage/\n",
    "\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать из терминала с разными параметрами\n",
    "* pymystem3 - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "\n",
    "    mystem_bin - путь к mystem, если их несколько\n",
    "    grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "    disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "    entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example)\n",
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "Стоп-слова -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию для препроцессинга текста, будем удалять стоп слова и пунктуацию, а в качестве токенизатора и лемматизатора воспользуемся майстемом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc_mystem(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]\n",
    "\n",
    "print(my_preproc_mystem(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pymorphy\n",
    "\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций.\n",
    "\n",
    "https://pymorphy2.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = pymorphy2_analyzer.parse(example)\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 11. Реализуйте функцию ```my_preproc_pymorphy``` по аналогии с ```my_preproc_mystem```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preproc_pymorphy(text):\n",
    "    ####### Ваш код здесь ########\n",
    "    raise NotImplementedError\n",
    "    ##############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mystem: {my_preproc_mystem(example)}')\n",
    "print(f'PyMorphy: {my_preproc_pymorphy(example)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частотность слов можно посмотреть, с помощью ```nltk.FreqDist```. Выведем топ 20 самых популярных токенов до и  после обработки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized = word_tokenize(s)\n",
    "alice_d_tokenized = nltk.FreqDist(tokenized)\n",
    "alice_d_tokenized.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_preproc = my_preproc_pymorphy(s)\n",
    "\n",
    "alice_d = nltk.FreqDist(alice_preproc)\n",
    "alice_d.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 12. Сколько раз встречается слово встречалось слово 'крокет' до и после обработки? Найдите изначальные слова, используя ```re.findall()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mystem vs. Pymorphy\n",
    "\n",
    "1) Mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) Снятие омонимии. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Стэммминг\n",
    "\n",
    "Для русского языка можно воспользоваться SnowballStemmer из пакета nltk.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "plurals = ['мухи', \"умирает\", \"мулы\", \"отказано\", \"умер\", \n",
    "           \"согласился\", \"владел\", \"унижен\", \"измерен\", \"встреча\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles = [stemmer.stem(plural) for plural in plurals]\n",
    "singles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Языковые модели. Модель биграм\n",
    "\n",
    "Какое слово в последовательности вероятнее: \n",
    "\n",
    "Поезд прибыл на\n",
    "* вокзал\n",
    "* север\n",
    "\n",
    "Какая последовательность вероятнее:\n",
    "* Вокзал прибыл поезд на\n",
    "* Поезд прибыл на вокзал\n",
    "\n",
    "### Приложения:\n",
    "* Задачи, в которых нужно обработать сложный и зашумленный вход: распознавание речи, распознавание сканированных и рукописных текстов;\n",
    "* Исправление опечаток\n",
    "* Машинный перевод\n",
    "* Подсказка при наборе \n",
    "\n",
    "### Виды моделей:\n",
    "* Счетные модели\n",
    "    * цепи Маркова\n",
    "* Нейронные модели, обычно реккурентные нейронные сети с LSTM/GRU\n",
    "* seq2seq архитектуры\n",
    "\n",
    "### Модель n-gram:\n",
    "\n",
    "Пусть $w_{1:n}=w_1,\\ldots,w_m$ – последовательность слов.\n",
    "\n",
    "Цепное правило:\n",
    "$ P(w_{1:m}) = P(w_1) P(w_2 | w_1) P(w_3 | w_{1:2}) \\ldots P(w_m | w_{1:m-1}) = \\prod_{k=1}^{m} P(w_k | w_{1:k-1}) $\n",
    "\n",
    "Но оценить $P(w_k | w_{1:k-1})$ не легче! \n",
    "\n",
    "Переходим к $n$-грамам: $P(w_{i+1} | w_{1:i}) \\approx P(w_{i+1} | w_{i-n:i})  $ , то есть, учитываем $n-1$ предыдущее слово. \n",
    "\n",
    "Модель\n",
    "* униграм: $P(w_k)$\n",
    "* биграм: $P(w_k | w_{k-1})$\n",
    "* триграм: $P(w_k | w_{k-1} w_{k-2})$\n",
    "\n",
    "\n",
    "Т.е. используем Марковские допущения о длине запоминаемой цепочки.\n",
    "\n",
    "* Вероятность следующего слова в последовательности: $ P(w_{i+1} | w_{1:i}) \\approx P(w_{i-n:i}) $\n",
    "* Вероятность всей последовательности слов: $P(w_{1:n}) = \\prod_{k=1}^l P(w_k | w_{k-n+1: k-1}) $\n",
    "\n",
    "### Качество модели  $n$-грам\n",
    "\n",
    "Перплексия: насколько хорошо модель предсказывает выборку. Чем ниже значение перплексии, тем лучше.\n",
    "\n",
    "$PP(\\texttt{LM}) = 2 ^ {-\\frac{1}{m} \\log_2 \\texttt{LM} (w_i | w_{1:i-1})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассмотрим модель биграм, используя библиотеку NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dinos.txt\") as f:\n",
    "    names = [name.strip().lower() for name in f.readlines()]\n",
    "    print(names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получить информацию о количестве символов можно, используя ```nltk.FreqDist```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [char  for name in names for char in name]\n",
    "freq = nltk.FreqDist(chars)\n",
    "\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее вероятный следующий токен можно получить с помощью  ```nltk.ConditionalFreqDist``` и ```nltk.ConditionalProbDist```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))\n",
    "cfreq['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)\n",
    "print('p(a,u) = %1.4f' % cprob['a'].prob('u'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно порождать случайные символы с учётом предыдущих:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob['a'].generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 13. Напишите функцию для оценки вероятности имени динозавра и найдите наиболее вероятное имя из загруженного списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 14. Напишите функцию для генерации  имени динозавра фиксированной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Ваш код здесь ########\n",
    "raise NotImplementedError\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
